# IND ENG 135 Final Project

## Volvo Social Media Analyzer - Twitter

Team Member:

- Xingyu Jin < xingyu.jin21@berkeley.edu >
- Mingyue Tang < mingyue_tang@berkeley.edu >
- Ruochen Liu < ruochen99@berkeley.edu >
- Ilene Kung < ilenekung@berkeley.edu >
- Yichu Chen < sterlingyichuchen@berkeley.edu >
- Neil Rabb < neil.rabb@berkeley.edu >

### Project Background

Social media is an important method through which the public share their lives and express their opinions. Among all kinds of social media platforms, Twitter is one of the most popular one where a company can get insights about what the public is thinking through their comments online. In this project, we aim to help Volvo team to better understand the social media contents collected on Twitter about Volvo and their products, provide visualizations as well as representative models to dig into data's essence, and equip Volvo's business team with a comprehensive and customizable tool for monitoring population attitude and improving commercial strategy accordingly.

Our project utilizes web-crawling algorithms, Natural Language Processing techniques, sentimental analysis, time series model, and other statistical and machine learning models to conduct EDA and prediction on the collected data set. As our final product, we developed a dashboard which allows users to customize filters and get data driven results accordingly.

### Code Structure

```
.
|____data_processing_notebooks     # Previous versions of data processing functions in ipython notebook
|
|____full_stack_server             # Main functions rending final product (frontend + backend)
| |____dao                         # Data Access Objects
| | |____mysql_processor.py        # processor handling reading and writing to database
| | |____twitter_crawler.py        # real-time web crawler for obtaining Twitter Data
| | |____twitter_processor.py      # data processor to abstract storage layer and  essential data upon request
| |
| |____handler                     # All handler functions dealing with main server logic
| | |____account_page_handler.py   # All functions related to handling account page API requests
| | |____mention_page_handler.py   # All functions related to handling mention page API requests
| |
| |____idl                         # Interface Description Language
| | |____service.proto             # ProtoBuf messages defining RPC services
| | |____view.proto                # ProtoBuf messages defining API request & response elements
| |
| |____pbgen                       # Serializer and structured data generated by ProtoBuf
| | |____service_pb2.py            
| | |____view_pb2.py
| |
| |____templates                   # Frontend Server Body handling styles and interaction functions
| |
| |____volvo_social_media_analyzer # Backend Server Body handling routings and requests
| | |____[__init__.py]             
| | |____settings.py               # Related Server settings for Django framework
| | |____urls.py                   # Router to handler HTTP requests
| | |____views.py                  # Request handling views
| | |____wsgi.py                   # Exposes the WSGI callable as a module-level variable
| |
| |____cronjob.py                  # Cronjob framework for keeping database updated
| |____manage.py                   # Main function to run server and listen to http requests
|
|____requirements.txt              # All external libaries needed for running this project
```

### Twitter Web Crawler

In order to bypass restrictions of Twitter API, such amount of tweets, QPS and time range, our crawler fetching the content directly from the HTML public pages, then parse the content we want. We built a pipeline to scrape, pre-preproces and output sentiment scores. We are using two main datasets, one includes all tweets about Volvo for 3 months (volvo701-1001.csv), one includes tweets from @VolvoCarUSA for 4 years(VolvoCarUSA.csv). 

### Twitter Data Processor

#### Data cleaning 

We start with filtering out ads. Our cleaning function removes mentions, punctuation, digits, stopwords and urls, changes emoji into one words, change letters to lowercase, and normalize text. 

#### Exploratory Data Analysis (EDA)

  ##### Tweets about Volvo: 
    1. Pie chart for main sources (geographically) 
    2. Major statistics (Num of tweets, retweets, likes, replies per day) 
    3. Time series : Daily and weekly tweet freq count 
    4. Histogram for Tweets sent by weekday and Tweets sent by hour of the day (in UTC) 
    6. Tweets that got top 10 retweeted/ repied/ liked 
    7. Bar chart for top active and influential users 
    8. wordcloud 
    
   ##### Tweets from Volvo: 
    1. Most mentioned users
    2. Most used hastags
    3. Tweets with most likes/ retweets/ replies 
 
 
#### Sentiment Analysis

First, we ranked the frequency of positive, neutral, and positive words with a labeled dataset. After deleting stop words, punctuations, and filler words, we were left with the most commonly appeared words from the three categories. Based on the frequency, we then assigned a specific score representing the strength/relevance of that word to a specific sentiment (positive: 0-1, neutral:0, negative:-1-0). Based on this logic, we utilized TextBlob to calculate subjectivity and polarity of each sentence and evaluate the sentiment of each tweet after EDA. We also added “slightly positive” and “slightly negative” to further classify tweets based on the magnitude of their sentiments, making it easier for the team to prioritize the most pressing issues in the Dashboard.

We grouped the tweets by car models that were provided by the mentors from Volvo. Then, by giving a sentiment score to every tweet in each group, Volvo will know that each car model’s feedback is positive or negative. We also group the tweets by country and analyze their sentiment scores, so Volvo knows which countries they need to target in order to improve its performance.

#### Time Series Prediction

With the existing data on daily average sentiment score of Tweets about Volvo, we developed a time series model to predict the average sentiment score of each day in the upcoming week. Through such time-sensitive prediction, we are able to capture an overall trend of the public's attitude on Volvo in general. If the trend of average sentiment score is going down and would reach "negative" in a week, the alert system will be triggered and suggests Volvo's team to pinpoint the issue.

### Final Product

We generalized all data processing functions and machine learning models explored in the EDA process and developed a well-functional dashboard as our final product. The dashboard is strongly customizable and thus capable of providing interesting insights from social media content to Volvo's team. The product is developed under separate frontend, backend, and database server, and the communication between layers are highly abstracted to ensure functionality and privacy.

#### Frontend Server

#### Backend Server

The backend server is built through the Python Django framework to handle HTTP requests sent from the frontend server. All logics are handled through two main layers: logic handlers and data accessing objects (DAO). DAO is designed specifically to interact with our database, reading from and writing to the MySQL server storing all relevant data. A logic handler must access data through DAO so that it is easier to control authority and keep the database clean. While reading from the database is straightforward and less challenging, we developed thread-safe database writing algorithms to keep everything clean and up-to-date. We utilize an offline update with Cron Job deployed on our server. The Cron Job will periodically update our data everyday under a predefined Crawling-Processing-Writing pipeline. 

Logic handlers provide main functionality of our product and provide HTTP response to the front end server. All HTTP requests and responses are serialized and formatted with Google Protocol Buffer v3 under the API defined ahead of time. 
